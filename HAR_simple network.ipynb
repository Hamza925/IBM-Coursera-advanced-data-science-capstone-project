{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Deep learning Model for our Data.\n",
    "In this notebook we build a simple MLP and evaluate the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "X_train = pandas.read_csv(\"Downloads/Datasets/UCI HAR Dataset/UCI HAR Dataset/train/X_train.txt\", delim_whitespace=True, header=None)\n",
    "y_train = pandas.read_csv(\"Downloads/Datasets/UCI HAR Dataset/UCI HAR Dataset/train/y_train.txt\", delim_whitespace=True, header=None)\n",
    "X_test = pandas.read_csv(\"Downloads/Datasets/UCI HAR Dataset/UCI HAR Dataset/test/X_test.txt\", delim_whitespace=True, header=None)\n",
    "y_test = pandas.read_csv(\"Downloads/Datasets/UCI HAR Dataset/UCI HAR Dataset/test/y_test.txt\", delim_whitespace=True, header=None)\n",
    "\n",
    "X_train = numpy.array(X_train)\n",
    "y_train = numpy.array(y_train)\n",
    "X_test = numpy.array(X_test)\n",
    "y_test = numpy.array(y_test)\n",
    "y_train = y_train.flatten()\n",
    "y_test = y_test.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7352, 561), (7352,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 220).fit(X_train)\n",
    "scalar = StandardScaler().fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scalar.transform(X_train)\n",
    "X_test = scalar.transform(X_test)\n",
    "X_train = pca.transform(X_train)\n",
    "X_test = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build a simple MLP with single hidden layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\hamza-acer\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(220, input_dim=220, kernel_initializer='normal', activation='softmax'))\n",
    "model.add(Dense(512, kernel_initializer='normal', activation='softmax'))\n",
    "model.add(Dense(1, kernel_initializer='normal'))\n",
    "# Compile model\n",
    "model.compile(loss='mean_squared_error', optimizer='adam',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model for 50 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\hamza-acer\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/50\n",
      "7352/7352 [==============================] - 1s 202us/step - loss: 14.6386 - acc: 0.0000e+00\n",
      "Epoch 2/50\n",
      "7352/7352 [==============================] - 1s 153us/step - loss: 11.6108 - acc: 0.1602\n",
      "Epoch 3/50\n",
      "7352/7352 [==============================] - 1s 148us/step - loss: 9.0808 - acc: 0.1668\n",
      "Epoch 4/50\n",
      "7352/7352 [==============================] - 1s 148us/step - loss: 7.0209 - acc: 0.1515\n",
      "Epoch 5/50\n",
      "7352/7352 [==============================] - 1s 157us/step - loss: 5.2586 - acc: 0.1459\n",
      "Epoch 6/50\n",
      "7352/7352 [==============================] - 1s 154us/step - loss: 3.9540 - acc: 0.1362\n",
      "Epoch 7/50\n",
      "7352/7352 [==============================] - 1s 150us/step - loss: 3.2790 - acc: 0.1353\n",
      "Epoch 8/50\n",
      "7352/7352 [==============================] - 1s 156us/step - loss: 2.0183 - acc: 0.2395\n",
      "Epoch 9/50\n",
      "7352/7352 [==============================] - 1s 153us/step - loss: 1.3376 - acc: 0.3206\n",
      "Epoch 10/50\n",
      "7352/7352 [==============================] - 1s 155us/step - loss: 0.9390 - acc: 0.3215\n",
      "Epoch 11/50\n",
      "7352/7352 [==============================] - 1s 153us/step - loss: 0.7439 - acc: 0.3331\n",
      "Epoch 12/50\n",
      "7352/7352 [==============================] - 1s 154us/step - loss: 0.6810 - acc: 0.3330\n",
      "Epoch 13/50\n",
      "7352/7352 [==============================] - 1s 150us/step - loss: 0.6666 - acc: 0.3332\n",
      "Epoch 14/50\n",
      "7352/7352 [==============================] - 1s 154us/step - loss: 0.6410 - acc: 0.3449\n",
      "Epoch 15/50\n",
      "7352/7352 [==============================] - 1s 165us/step - loss: 0.4628 - acc: 0.4589\n",
      "Epoch 16/50\n",
      "7352/7352 [==============================] - 1s 149us/step - loss: 0.3885 - acc: 0.5287\n",
      "Epoch 17/50\n",
      "7352/7352 [==============================] - 1s 154us/step - loss: 0.3483 - acc: 0.6748\n",
      "Epoch 18/50\n",
      "7352/7352 [==============================] - 1s 159us/step - loss: 0.1951 - acc: 0.7616\n",
      "Epoch 19/50\n",
      "7352/7352 [==============================] - 1s 149us/step - loss: 0.1156 - acc: 0.8029\n",
      "Epoch 20/50\n",
      "7352/7352 [==============================] - 1s 155us/step - loss: 0.0869 - acc: 0.9083\n",
      "Epoch 21/50\n",
      "7352/7352 [==============================] - 1s 158us/step - loss: 0.0631 - acc: 0.9604\n",
      "Epoch 22/50\n",
      "7352/7352 [==============================] - 1s 156us/step - loss: 0.0426 - acc: 0.9698\n",
      "Epoch 23/50\n",
      "7352/7352 [==============================] - 1s 155us/step - loss: 0.0306 - acc: 0.9759\n",
      "Epoch 24/50\n",
      "7352/7352 [==============================] - 1s 157us/step - loss: 0.0266 - acc: 0.9780\n",
      "Epoch 25/50\n",
      "7352/7352 [==============================] - 1s 154us/step - loss: 0.0242 - acc: 0.9804\n",
      "Epoch 26/50\n",
      "7352/7352 [==============================] - 1s 153us/step - loss: 0.0230 - acc: 0.9823\n",
      "Epoch 27/50\n",
      "7352/7352 [==============================] - 1s 154us/step - loss: 0.0220 - acc: 0.9826\n",
      "Epoch 28/50\n",
      "7352/7352 [==============================] - 1s 158us/step - loss: 0.0215 - acc: 0.9837\n",
      "Epoch 29/50\n",
      "7352/7352 [==============================] - 1s 155us/step - loss: 0.0207 - acc: 0.9842\n",
      "Epoch 30/50\n",
      "7352/7352 [==============================] - 1s 159us/step - loss: 0.0207 - acc: 0.9863\n",
      "Epoch 31/50\n",
      "7352/7352 [==============================] - 1s 161us/step - loss: 0.0196 - acc: 0.9857\n",
      "Epoch 32/50\n",
      "7352/7352 [==============================] - 1s 158us/step - loss: 0.0189 - acc: 0.9863\n",
      "Epoch 33/50\n",
      "7352/7352 [==============================] - 1s 150us/step - loss: 0.0185 - acc: 0.9864\n",
      "Epoch 34/50\n",
      "7352/7352 [==============================] - 1s 155us/step - loss: 0.0183 - acc: 0.9869\n",
      "Epoch 35/50\n",
      "7352/7352 [==============================] - 1s 158us/step - loss: 0.0176 - acc: 0.9874\n",
      "Epoch 36/50\n",
      "7352/7352 [==============================] - 1s 148us/step - loss: 0.0169 - acc: 0.9882\n",
      "Epoch 37/50\n",
      "7352/7352 [==============================] - 1s 151us/step - loss: 0.0162 - acc: 0.9908\n",
      "Epoch 38/50\n",
      "7352/7352 [==============================] - 1s 158us/step - loss: 0.0159 - acc: 0.9908\n",
      "Epoch 39/50\n",
      "7352/7352 [==============================] - 1s 154us/step - loss: 0.0155 - acc: 0.9910\n",
      "Epoch 40/50\n",
      "7352/7352 [==============================] - 1s 148us/step - loss: 0.0148 - acc: 0.9909\n",
      "Epoch 41/50\n",
      "7352/7352 [==============================] - 1s 156us/step - loss: 0.0148 - acc: 0.9908\n",
      "Epoch 42/50\n",
      "7352/7352 [==============================] - 1s 157us/step - loss: 0.0141 - acc: 0.9905\n",
      "Epoch 43/50\n",
      "7352/7352 [==============================] - 1s 154us/step - loss: 0.0131 - acc: 0.9927\n",
      "Epoch 44/50\n",
      "7352/7352 [==============================] - 1s 160us/step - loss: 0.0138 - acc: 0.9922\n",
      "Epoch 45/50\n",
      "7352/7352 [==============================] - 1s 161us/step - loss: 0.0116 - acc: 0.9928\n",
      "Epoch 46/50\n",
      "7352/7352 [==============================] - 1s 156us/step - loss: 0.0110 - acc: 0.9937\n",
      "Epoch 47/50\n",
      "7352/7352 [==============================] - 1s 154us/step - loss: 0.0101 - acc: 0.9940\n",
      "Epoch 48/50\n",
      "7352/7352 [==============================] - 1s 156us/step - loss: 0.0095 - acc: 0.9955\n",
      "Epoch 49/50\n",
      "7352/7352 [==============================] - 1s 166us/step - loss: 0.0091 - acc: 0.9955\n",
      "Epoch 50/50\n",
      "7352/7352 [==============================] - 1s 172us/step - loss: 0.0085 - acc: 0.9951\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23fa10f8e48>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2947/2947 [==============================] - 0s 84us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.05507418746658018, 0.9528333898880217]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 220)               48620     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               113152    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 162,285\n",
      "Trainable params: 162,285\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
